
# Effective Modern C++

# 목차

#### 35. [스레드 기반 프로그래밍보다 과제 기반 프로그래밍을 선호하라](#item-35-스레드-기반-프로그래밍보다-과제-기반-프로그래밍을-선호하라)
#### 36. [비동기성이 필수일 때에는 std::launch::async 를 지정하라](#item-36-비동기성이-필수일-때에는-stdlaunchasync-를-지정하라)
#### 37. [std::thread 들은 모든 경로에서 합류 불가능하게 만들어라](#item-37-stdthread-들은-모든-경로에서-합류-불가능하게-만들어라)
#### 38. [스레드 핸들 소멸자들의 다양한 행동 방식을 주의하라](#item-38-스레드-핸들-소멸자들의-다양한-행동-방식을-주의하라)
#### 39. [단발성 사건 통신에는 void 미래 객체를 고려하라](#item-39-단발성-사건-통신에는-void-미래-객체를-고려하라)
#### 40. [동시성에는 std::atomic을 사용하고, volatile은 특별한 메모리에 사용하라](#item-40-동시성에는-stdatomic을-사용하고-volatile은-특별한-메모리에-사용하라)
#### 41. [이동이 저렴하고 항상 복사되는 복사 가능 매개변수에 대해서는 값 전달을 고려하라](#item-41-이동이-저렴하고-항상-복사되는-복사-가능-매개변수에-대해서는-값-전달을-고려하라)

#### 42. [삽입 대신 생성 삽입을 고려하라](#item-42-삽입-대신-생성-삽입을-고려하라)
---



# 7장. 동시성 API


## Item 35. 스레드 기반 프로그래밍보다 과제 기반 프로그래밍을 선호하라

 C++ 에서 함수를 비동기적으로 실행하는 두 가지 방법
```cpp
// thread 객체를 생성해서 그 객체에서 doAsyncWork 실행하는 방법
// 스레드 기반 프로그래밍
int doAsyncWork();
std::thread t(doAsyncWork);

// async 에 doAsyncWork 를 넘겨주는 방법
// 과제 기반 프로그래밍 
auto fut = std::async(doAsyncWork);
```

### 과제 기반 접근 방식이 스레드 기반 접근 방식보다 좋은 이유
- 과제 기반 접근 방식은 std::async 가 돌려주는 객체에서 get 멤버 함수로 접근 가능/ 스레드 기반 접근 방식에서는 접근 불가능
	- 특히 예외를 방출할 시 과제 기반은 get 을 통해 예외에 접근 가능하지만 스레드 기반은 프로그램이 죽음

- 과제 기반 접근 방식이 좀 더 높은 수준의 추상을 표현 -> 프로그래머가 세부적인 스레드 관리에서 벗어남

#### 스레드 용어 의미
- `하드웨어 스레드` 
	- 실제 계산을 수행하는 스레드, 현세대의 컴퓨터는 CPU 코어당 하나 이상의 하드웨어 스레드를 제공
- `소프트웨어 스레드(OS 스레드, 시스템 스레드)`
	- 운영체제가 하드웨어 스레드들에서 실행되는 모든 프로세서와 일정을 관리하는 데 사용
	- 하드웨어 스레드보다 많은 소프트웨어 스레드 생성 가능
	- 한 소프트웨어 스레드가 차단(blocking) 되어도, 차단되지 않은 다른 소프트웨어 스레드들을 실행함으로써 산출량을 향상 가능 
- `C++ 표준 라이브러리의 std::thread`
	- 하나의 C++ 프로세스 안에서 std::thread 객체는 바탕 소프트웨어 스레드에 대한 핸들로 작용
	- std::thread 객체가 널(null) 핸들을 나타내기도 함


### 스레드 관리 문제

#### 스레드가 부족할 경우 
```cpp
int doAsyncWork() noexcept;

std::thread t(doAsyncWork); // 사용 가능한 스레드가 없으면 예외 발생
```
소프트웨어 스레드는 제한된 자원으로 시스템이 제공할 수 있는 것보다 많은 소프트웨어 스레드를 생성하려 하면 std::system_error 예외가 발생한다. 이는 스레드에서 실행하고자 하는 함수가 예외를 던질 수 없는 경우에도 마찬가지이다.

-  doAsyncWork 를 현재 스레드에서 실행 -> 현재 스레드에 부하(load)가 과중하게 걸릴 수 있음.
	현재 스레드가 GUI 스레드라면 사용자 입력에 대한 반응성 문제 발생 가능
- 기존의 일부 소프트웨어 스레드가 완료되길 기다렸다가 std::thread를 새로 생성
	기존 스레드들이 doAsyncWork 가 수행하는 어떤 동작을 기다리고 있을 수 있음.

#### 과다구독

가용 스레드가 부족하지 않아도 `과다구독(oversubscription)` 때문에 문제가 발생할 수 있다. `과다구독`이란 실행 준비가 된(즉, 차단되지 않은) 소프트웨어 스레드가 하드웨어 스레드보다 많은 상황을 가리킨다. 
- 과다구독 발생
	- 스레드 스케줄러는 하드웨어상의 실행 시간을 여러 조각으로 나눠 소프트웨어 스레드에게 배분
	- 한 소프트웨어 스레드에 부여된 시간 조각이 끝나고 다른 소프트웨어 스레드의 시간 조각이 시작할 때 context switch(문맥 전환)이 수행
	- 과도한 context switch는 스레드 관리 부담이 증가하고, 다른 작업을 수행하는 여러 스레드가 같은 CPU를 사용함으로써 CPU 캐시가 '오염'되어 효율이 떨어짐


### std::async

`std::async` 를 사용한다면 스레드 관리 부담을 표준 라이브러리 구현자들에게 떠넘길 수 있다.
```cpp
auto fut = std::async(doAsyncWork);
```
이렇게 하면, 가용 스레드 부족 때문에 예외를 받을 가능성이 크게 줄어든다. 이 호출은 예외를 방출할 가능성이 거의 없음.
- std::async 는 새 소프트웨어 스레드를 생성하지 않을 수도 있다. 대신 std::async는 지정된 함수를 doAsyncWork의 결과가 필요한 스레드(즉, fut에 대해 get 이나 wait 를 호출하는 스레드) 에서 실행하라고 스케줄러에게 요청할 수 있음
- 합리적인 스케줄러는 시스템이 과다구독되었거나 스레드가 부족한 상황에서 그러한 자유의 장점
- 이러한 "함수를 결과가 필요한 스레드에서 실행"하는 기법을 적용하였을 때 부하 불균형 문제가 발생할 수 있음. 다만 스케줄러가 로드 밸런싱(load balancing) 문제와 관련하여 프로그래머들보다 더 상세히 알고 있을 가능성이 높음.
- GUI 스레드의 반응성이 문제가 될 수 있다. 그런 경우에는 std::launch::async 라는 시동 방침을 std::async에 넘겨주는 것이 바람직함. 그러면 실행하고자 하는 함수가 실제로 현재 스레드와 다른 스레드에서 실행됨.

**따라서, 다음과 같은 스레드를 직접 다루는 게 적합한 일부 경우를 제외하면, 과제 기반 설계를 선호!**

#### 스레드를 직접 다루는 경우
- 바탕 스레드 적용 라이브러리의 API에 접근해야 하는 경우
	- pthreads 라이브러리나 windows 스레드 라이브러리 API 는 C++ 에서 제공하는 API 보다 풍부한 기능 제공한다. 바탕 스레드 적용 라이브러리의 API 에 접근할 수 있도록, std::thread 객체는 native_handle 이라는 멤버 함수 제공한다. std::future(std::async 가 돌려주는) 에는 이런 기능이 없다.
	- 응용 프로그램의 스레드 사용량을 최적화해야 하는, 그리고 할 수 있어야 하는 경우
	- C++ 동시성 API가 제공하는 것 이상의 스레드 적용 기술을 구현해야 하는 경우
		- 특정 플랫폼에서 스레드 풀을 직접 구현해야 하는 경우 



## Item 36. 비동기성이 필수일 때에는 std::launch::async 를 지정하라

일반적으로, std::async 를 호출해서 어떤 함수를 비동기적으로 실행하겠다는 의도를 품고 있지만, 항상 그런 의미일 필요는 없다. std::async 호출은 함수를 어떤 `시동 방침(launch policy)`에 따라 실행한다는 좀 더 일반적인 의미를 가진다. 

- **std::launch::async** : 함수는 반드시 비동기적으로, 다시 말해 다른 스레드에서 실행된다.
- **std::launch::deferred** : 함수는 std::async가 돌려준 미래 객체(std::future)에 대해 get이나 wait가 호출될 때만 실행될 수 있다. 다시 말해, 함수는 그러한 호출이 일어날 때까지 지연된다. get이나 wait가 호출되면 함수는 동기적으로 실행된다. 즉, 호출자는 함수의 실행이 종료될 때까지 차단된다. get이나 wait가 호출되지 않으면 함수는 실행되지 않는다. 

기본 시동 방침은 둘을 OR 로 결합한 것이다. 따라서 다음 두 호출은 같은 의미이다.
```cpp
auto fut1 = std::async(f); // 함수 f 를 기본 시동 방침으로 실행
auto fut2 = std::async(std::launch::async | std::launch::deferred, f);
```

#### 기본 시동 방침 실행

결과적으로 기본 시동 방침에서 함수 f 는 비동기적으로 실행될 수도 있고 동기적으로 실행될 수도 있다. 그런데 std::async 를 기본 시동 방침과 함께 사용하면 흥미로운 영향이 생긴다. 

다음 코드가 스레드 t 에서 실행된다고 하자.
```cpp
auto fut = std::async(f);
```
이때 생길 수 있는 상황은,

- f가 지연 실행될 수도 있으므로, **f가 t와 동시에 실행될지 예측하는 것이 불가능하다.**
- **f가 fut에 대해 get이나 wait를 호출하는 스레드와는 다른 스레드에서 실행될지 예측하는 것이 불가능하다.**
  t가 그 스레드라고 할 때, f가 t와는 다른 스레드에서 실행될지는 예측할 수 없다.
- fut에 대한 get이나 wait 호출이 일어난다는 보장이 없을 수도 있으므로, **f가 반드시 실행될 것인지 예측하는 것이 불가능할 수도 있다.**

기본 시동 방침의 스케줄링 유연성이 thread_local 변수들의 사용과는 궁합이 잘 맞지 않는 경우도 있다. f 에 그런 스레드 지역 저장소(thread-local storage, TLS) 를 읽거나 쓰는 코드가 있다고 할 때, 그 코드가 어떤 스레드의 지역 변수에 접근할 지 예측할 수 없기 때문이다.
```cpp
auto fut = std::async(f); // f의 TLS가 독립적인 스레드의 것일 수도 있고,
						  // fut에 대해 get이나 wait를 호출하는 스레드의 것일 수도 있다
```
이 유연성은 또한 만료 시간이 있는 wait 기반 루프에도 영향을 미친다. 지연된 과제에 대해  wait_for 나 wait_until 을 호출하면 std::future_status::deferred 라는 값이 반환되기 때문이다. 이 때문에, 다음 코드에서 무한 실행될 수도 있다.

- f가 std::async 를 호출한 스레드와 동시에 실행된다면(즉, f 를 시동 방침 std::launch::async로 실행한다면), f 자체가 무한 실행되지 않는 이상 문제가 없다.
- 하지만 f가 지연된다면, fut.wait_for 는 항상 std::future_status::deferred 를 돌려준다. 따라서 루프가 종료되지 않는다.
```cpp
using namespace std::literals;

// f는 1초간 수면 후 반환된다.
void f()	
{
	std::this_thread::sleep_for(1s);
}
auto fut = std::async(f);	// f를 비동기적으로 (개념상으로는) 실행한다

// f의 실행이 끝날 때까지 루프를 반복함
while(fut.wait_for(100ms) != std::future_status::ready)
{
	...
}
```

이러한 문제의 해결 방법은 그냥 std::async 호출이 돌려준 미래 객체를 이용해서 해당 과제가 지연되었는지 점검하고, 지연되었다면 시간 만료 기반 루프에 진입하지 않게 하는 것이다. 
```cpp
auto fut = std::async(f);	// 이전과 동일

if (fut.wait_for(0s) == std::future_status::deferred)	// 과제가 지연되었으면
{
	...	// fut에 wait나 get을 적용해서 f를 동기적으로 호출
}
else	// 지연되지 않았다면
{
	while(fut.wait_for(100ms) != std::future_status::ready)	// 무한 루프는 불가능
	{
		...	// 과제가 지연되지도 않았고 준비되지도 않았으므로
			// 준비될 때까지 동시적 작업을 수행한다.
	}
	...	// fut이 준비되었다.
}
```

**따라서 어떤 과제에 대해 기본 시동 방침과 함께 std::async를 사용하는 것은 다음 조건이 모두 성립할 때만 적합**
- 과제가 get이나 wait를 호출하는 스레드와 반드시 동기적으로 실행되어야 하는 것이 아니다.
- 여러 스레드 중 어떤 스레드의 thread_local 변수들을 읽고 쓰는지가 중요하지 않다.
- std::async가 돌려준 미래 객체에 대해 get이나 wait가 반드시 호출된다는 보장이 있거나, 과제가 전혀 실행되지 않아도 괜찮다.
- 과제가 지연된 상태일 수도 있다는 점이 wait_for나 wait_until을 사용하는 코드에 반영되어 있다.

위의 조건 중 하나라도 성립하지 않는다면 std::async 가 주어진 과제를 진정으로 비동기적으로 실행하도록 강제할 필요가 있다. 그렇게 하는 방법은, std::launch::async를 시동 방침으로 지정해서 std::async를 호출하는 것이다.

```cpp
auto fut = std::async(std::launch::async, f); // f를 비동기 적으로 호출
```
함수를 호출할 때마다  std::launch::async 를 사용하지 않아도 되는 함수를 정의해보자
```cpp
// C++ 11 버전, C++ 14 버전에서는 리턴 타입을  auto로 대체 가능
template<typename F, typename... Ts>
inline
std::future<typename std::result_of<F(Ts...)>::type>
reallyAsync(F&& f, Ts&&...  params)
{
	return std::async(std::launch::async,	// 비동기적 f 호출을 위한 미래 객체를 리턴
					  std::forward<F>(f),
					  std::forward<Ts>(params)...);
}

auto fut = reallyAsync(f);
```


## Item 37. std::thread 들은 모든 경로에서 합류 불가능하게 만들어라

모든 std::thread 객체는 합류 가능(joinable) 상태이거나 합류 불가능(unjoinable) 상태이다. 
합류 가능 std::thread는 바탕 실행 스레드 중 현재 실행 중(running)이거나 실행 중 상태로 전이할 수 있는 스레드에 대응된다. 예를 들어, 차단된 상태이거나 실행 일정을 기다리는 중인 바탕 스레드에 해당하는 std:;thread는 합류 가능 상태이다.  그리고 실행이 완료된 바탕 스레드에 해당하는 std::thread 객체도 합류 가능으로 간주한다.

합류 불가능한 std::thread 객체로는 다음과 같은 것들이 있다.
- **기본 생성된 std::thread**
	- 그런 std::thread 객체에는 실행할 함수가 없으므로 바탕 실행 스레드와는 대응되지 않는다.
- **다른 std::thread 객체로 이동된 후의 std::thread 객체**
	- 이동의 결과로, 원본 std::thread에 대응되던 바탕 스레드는 대상 std::thread의 바탕 스레드가 된다.
- **join에 의해 합류된 std::thread**
	- join 이후의 std::thread 객체는 실행이 완료된 바탕 실행 스레드에 대응되지 않는다.
- **detach 에 의해 탈착된 std::thread**
	- detach는 std::thread 객체와 그에 대응되는 바탕 스레드 사이의 연결을 끊는다.

std::thread 의 합류 가능성이 중요한 이유는, 만일 합류 가능한 스레드의 소멸자가 호출되면 프로그램 실행이 종료된다는 것이다. 아래의 코드에서는 필터링과 doWork 에서 조건들의 만족 여부를 점검하는 것을 별개의 스레드에서 동시에 실행할 것이다.
```cpp
constexpr auto tenMillion = 10'000'000;

bool doWork(std::function<bool(int)> filter,
			int maxVal = temMillion)
{
	std::vector<int> goodVals;	// 필터를 통과한 값들
	
	std::thread t([&filter, maxVal, &goodVals]	// goodVals에 값들을 채운다
				  {
					  for(auto i = 0; i <= maxVal; ++i)
					  { if (filter(i)) goodVals.push_back(i); }
				  });
				  
	auto nh = t.native_handle();	// t의 네이티브 핸들을 이용해 t의 우선순위 설정
	...
	if (conditionsAreSatisfied()) {	// 조건들이 만족되었다면 t의 완료를 기다린다
		t.join();
		performComputation(goodVals);
		return true;
	}
	return false;
}
```
위의 코드에서 conditionsAreSatisfied 가 true 를 돌려주는 문제가 없다. 그러나 false 를 돌려주거나 예외를 던진다면 실행의 흐림이 doWork 의 끝에 도달해서 std::thread 객체 t 의 소멸자가 호출되는데, 문제는 이때의 t가 여전히 합류 가능 상태라는 점이다. 이 때문에 프로그램 실행이 종료된다.
소멸자가 왜 이런 식으로 행동하는 이유는 다른 두 옵션이 명백히 더 나쁘기 때문이다.
- 암묵적 join
	- std::thread 의 소멸자가 바탕 비동기 실행 스레드의 완료를 기다리게 하는 것이다. 이 경우, 실제로는 추적하기 어려운 성능 이상이 나타낼 수 있다. 
	- conditionsAreSatisfied()가 이미 false 를 돌려주었는데도 모든 값에 필터가 적용되길 doWork 가 기다리는 것은 직관적이지 않다.
- 암묵적 detach
	- std::thread 의 소멸자가 std::thread 객체와 바탕 실행 스레드 사이의 연결을 끊게 하는 것이다. 이 경우 바탕 스레드가 실행을 계속할 수 있다. 
	- doWork 에서 goodVals는 지역 변수인데, 람다가 참조에 의해 갈무리해서 자신의 본문 안에서 수정한다(push_back 호출을 통해). 람다가 비동기적으로 실행되는 도중에 conditionsAreSatisfied()가 false 를 돌려주면 doWork 가 리턴되며, 따라서 지역 변수들(goodVals 포함)이 파괴된다. 이제 doWork의 스택 프레임이 pop되어 실행의 흐름이 doWork의 호출 지점 다음으로 넘어가겠지만, 해당 스레드는 doWork의 호출 지점에서 계속 실행된다. 호출된 지점 다음에 doWork 스택 프레임이 차지하던 메모리의 일부 또는 전부를 사용하는 함수 f 가 실행된다고 하자. goodVals 에 대해 push_back 을 호출하는 람다는 비동기적으로 계속 실행이 될 것이고, 함수 f 의 관점에서 이는 자신의 스택 프레임에 있는 메모리의 내용이 갑자기 변하는 기현상이 발생.

**표준 위원회는 합류 가능 스레드를 파괴했을 때의 결과가 절망적이므로, 그런 파괴를 아예 금지하기로(프로그램이 종료) 했다.**

따라서, std::thread 객체를 사용할 때 그 객체가 그것이 정의된 범위 바깥의 모든 경로에서 합류 불가능으로 만드는 것은 프로그래머의 책임이다( return, continue, break, goto, 예외 등).

한 범위의 바깥으로 나가는 모든 경로에서 어떤 동작이 반드시 수행되어야 할 때의 흔히 사용하는 접근 방식은 그 동작을 지역 객체의 소멸자 안에 넣는 것이다. 그런 객체를 `RAII 객체`라고 부르고, 그런 객체의 클래스를 `RAII 클래스`라고 부른다(RAII, Resource Acquisition Is Initialization). 
이는 표준 라이브러리에서 흔하지만, std::thread 객체에 대한 표준 RAII 클래스는 없다. 아마도 이는, join 과 detach 둘 다 기본 옵션으로 선택하지 않은 표준 위원회로서는 std::thread 객체에 대한 표준적인 RAII 클래스가 어떤 것이어야 할지 파악할 수 없었기 때문일 것이다.

std::thread 를 위한 RAII 클래스인 ThreadRAII 클래스를 구현하면 다음과 같다.

```cpp
class ThreadRAII {
public:
	enum class DtorAction { join, detach };
	ThreadRAII(std::thread&& t, DtorAction a)	// 소멸자에서 t에 대해 동작 a 수행
	: action(a), t(std::move(t)) {}

	~ThreadRAII()
	{
		if (t.joiniable()) {
			if (action == DtorAction::join) {
				t.join();
			} else {
				t.detach();
			}
		}
	}
	ThreadRAII(ThreadRAII&&) = default;				// 소멸자를 선언하므로 이동연산을 위해 명시적 선언
	ThreadRAII& operator=(ThreadRAII&&) = default;	// 따라서 이동 연산들을 지원
	
	std::thread& get() { return t; }
private:
	DtorAction action;
	std::thread t;
}

```
- 생성자는 std::thread 오른값만 받는다. 그것을 ThreadRAII 객체로 이동할 것이므로
- 생성자의 매개변수들은 호출자가 직관적으로 기억할 수 있는 순서로 선언되어 있다. 그러나 멤버 초기화 목록은 자료 멤버들이 선언된 순서를 따른다. 따라서 std::thread 객체가 마지막으로 선언되어 있다. 그리고 std::thread 객체는 초기화되자마자 해당 함수를 실행할 수도 있으므로, 클래스에서 std::thread 자료 멤버는 항상 제일 마지막에 선언하는 것이 좋다.
- ThreadRAII 는 바탕 std::thread 객체에 접근할 수 있는 get 함수를 제공한다. 이는 스마트 포인터 get 과 비슷하다.
- ThreadRAII 소멸자는 std::thread 객체 t에 대해 멤버 함수를 호출하기 전에 먼저 t 가 합류 가능한지부터 확인한다. 합류 불가능 스레드에 대해 join 이나 detach 를 호출하면 미정의 행동이 나오기 때문이다.
- 소멸자의 다음 부분에서 경쟁 조건(race condition)이 존재하지 않을까? 즉, joinable 의 실행과 join 또는 detach 호출 사이에 다른 스레드가 t 를 합류 불가능하게 만들면 경쟁 조건이 성립하지 않을까? 라고 걱정할 필요는 없다.
	- 합류 가능한 std::thread 객체는 오직 멤버 함수 호출(join이나 detach) 또는 이동 연산에 의해서만 합류 불가능한 상태로 변할 수 있다. 
	- ThreadRAII 객체의 소멸자가 호출되는 시점에서는 그 객체에 대해 그런 멤버 함수를 호출할 만한 스레드가 남아 있지 않아야 한다. 만일 그런 호출들이 동시에 일어나면 경쟁이 발생하겠지만, 그런 호출이 일어나는 곳은 소멸자 안이 아니라 하나의 객체에 대해 동시에 두 멤버 함수(하나는 소멸자, 또 하나는 다른 어떤 멤버 함수)를 실행하려는 클라이언트 코드이다.
	- 일반적으로 하나의 객체에 대해 여러 멤버 함수를 동시에 호출하는 것은 그 멤버 변수 함수들이 const 멤버 함수인 경우에만 안전하다.

doWork 예제에 ThreadRAII 를 적용한 코드는 다음과 같다.

```cpp
bool doWork(std::function<bool(int)> filter,
			int maxVal = temMillion)
{
	std::vector<int> goodVals;	// 필터를 통과한 값들
	
	ThreadRAII t(
		std::thread([&filter, maxVal, &goodVals]	// goodVals에 값들을 채운다
					{
						for (auto i = 0; i <= maxVal; ++i)
							{ if (filter(i)) goodVals.push_back(i); }
				  }),
				  ThreadRAII::DtorAction::join
	);
				  
	auto nh = t.get().native_handle();	// t의 네이티브 핸들을 이용해 t의 우선순위 설정
	...
	if (conditionsAreSatisfied()) {	// 조건들이 만족되었다면 t의 완료를 기다린다
		t.get().join();
		performComputation(goodVals);
		return true;
	}
	return false;
}
``` 

ThreadRAII 소멸자가 비동기 실행 스레드에 대해 join을 호출하도록 했는데, join 을 사용하면 성능 이상을 유발할 수 있지만 detach 로 인해 발생할 수 있는 미정의 행동과 프로그램 종료보다는 덜 나쁘다. 물론 join 으로 인해 프로그램이 멈추는(hang) 문제가 발생할 수 있지만, 이는 가로챌 수 있는 스레드(interruptible thread) 를 사용해야 하지만 c++11에서는 지원하지 않고 책의 범위를 넘어선다.




## Item 38. 스레드 핸들 소멸자들의 다양한 행동 방식을 주의하라

합류 가능한 std::thread 는 바탕 시스템의 실행 스레드에 대응된다. 그와 비슷하게, 지연되지 않은 과제에 대한 미래 객체도 시스템 스레드에 대응된다. 따라서 std::thread 객체와 미래 객체 모두 시스템 스레드에 대한 **핸들(handle)** 이라고 할 수 있다.

하지만 미래 객체의 소멸자는 어떨 때는 암묵적으로 join 을 수행한 것과 같은 결과를 내고, 어떨 때에는 마치 암묵적으로 detach 를 수행한 것과 같은 결과를 낸다. 그렇다고 프로그램이 종료되는 일은 없다.

우선, 미래 객체는 피호출자가 결과를 호출자에게 전송하는 통신 채널의 한 쪽 끝이라는 점이다.
피호출자는 자신의 계산 결과를 그 통신 채널에 기록(std::promise). 그리고 호출자는 미래 객체를 이용해서 결과를 읽는다.
```
//             미래 객체                   std::promise
//   |호출자| <---------------------------------------- |피호출자|
```

- 호출자가 해당 미래 객체에 대해 get 을 호출하기 전에 피호출자의 실행이 끝날 수도 있어 std::promise 에 피호출자의 결과를 저장할 수 없다.
-  또한 호출자의 미래 객체에 저장할 수도 없다. 전달받은 std::future 가 std::shared_future 로 여러 번 복사할 수 있기 때문이다. 
- 따라서 공유 상태(shared state ) 라고 부르는 제 3의 장소에 피호출자의 결과를 저장한다. 
```
//             미래 객체             공유상태             std::promise
//   |호출자| <------------------|피호출자의 결과|-------------------- |피호출자|
```


####  미래 객체 소멸자의 행동은 그 미래 객체와 연관된 공유 상태가 결정하게 된다.

- **std::async 를 통해서 시동된 비지연(지연되지 않은) 과제에 대한 공유 상태를 참조하는 마지막 미래 객체의 소멸자는 과제가 완료될 때까지 차단한다.** 
	- 미래 객체의 소멸자는 비동기적으로 실행되고 있는 스레드에 대해 암묵적 join  수행
- **다른 모든 미래 객체의 소멸자는 그냥 해당 미래 객체를 파괴한다.**
	- 비동기적으로 실행되고 있는 과제의 경우 이는 바탕 스레드에 암묵적 detach 를 수행하는 것과 비슷한 동작

간단히 말해서, 예외적인 상황을 제외하면 그냥 미래 객체의 소멸자가 미래 객체를 파괴한다는 것이다. 소멸자는 join, detach, 실행 그 무엇도 하지 않고, 그냥 미래 객체의 자료 멤버들만 파괴한다.


#### 미래 객체를 파괴하는 정상 행동에 대한 예외가 발생하는 조건

- **미래 객체가 std::async 호출에 의해 생성된 공유 상태를 참조한다.**
- **과제의 시동 방침이 std::launch::async 이다.** ( 명시적이든 암묵적이든)
- **미래 객체가 공유 상태를 참조하는 마지막 미래 객체이다**
	- std::future 는 항상 성립한다
	- std::shared_future 의 경우, 미래 객체가 파괴되는 동안 같은 공유 상태를 다른 std::shared_future 가 참조하고 있다면, 파괴되는 미래 객체는 정상 행동을 따른다(즉, 그냥 자료 멤버들만 파괴).

위의 조건들을 만족하는 경우, 비동기적으로 실행되는 과제가 완료될 때까지 소멸자의 실행이 차단된다. 즉, std::async 로 생성한 과제를 실행하는 스레드에 대해 암묵적으로 join 을 호출되는 것에 해당된다.


#### 미래 객체 소멸자

```cpp
// 이 컨테이너는 소멸자에서 차단될 수도 있다;  
// 컨테이너에 담긴 하나 이상의 미래 객체들이 std::async 를 통해  
// 시동된 비지연 과제에 대한 공유 상태를 참조할 수도 있기 때문 
std::vector<std::future<void>> futs; 
// Widget 객체의 소멸자가 차단될 수도 있다  
class Widget {  
public: 
... 
private: 
	std::shared_future<double> fut; 
};
```
- 임의의 미래 객체에 대해 그 소멸자가 비동기적으로 실행되는 과제의 완료를 기다리느라 차단될 것인지 알아내는 것은 불가능하다. 
- 소멸자의 특별한 행동은 공유 상태가 std::async 호출에서 비롯된 경우에만 일어날 수 있지만, 다른 여러 원인으로도 공유 상태가 생성될 수 있다. 
- std::packaged_tack 객체는 주어진 함수(또는 호출 가능 객체)를 비동기적으로 실행할 수 있도록 '포장' 하는데, 포장된 함수의 실행 결과는 공유 상태에 저장된다.

```cpp
{ 
	// 실행할 함수  
	int calcValue(); 

	// 비동기적 실행을 위해 calcValue 포장  
	std::packaged_task<int()> pt(calcValue); 
	// pt 에 대한 미래 객체를 얻는다  
	auto fut = pt.get_future(); 
	// std::packaged_task 는 복사 불가; 오른값으로 캐스팅해야 함  
	std::thread t(std::move(pt)); 
	...
}
```

- 다음 코드의 미래객체 fut 가 std::async 호출로 만들어진 공유 상태를 참조하지 않음이 명확하므로, 해당 소멸자는 정상적으로 행동한다. 
- 위의 "..." 부분에서는 크게 3가지 일이 일어날 수 있다.
	- **t 에 대해 아무 일도 일어나지 않음** : t 는 합류 가능 스레드가 되어, 프로그램이 종료됨
	- **t 에 대해 join 수행** : join 을 수행한다면 fut의 소멸자에서는 join 을 수행할 필요없음. 따라서 차단될 이유 없음
	- **t 에 대해 detach 수행** : 위의 join 과 마찬가지

- 즉, std::packaged_task 에 의해 만들어진 공유 상태를 참조하는 미래 객체가 있다면, 소멸자는 특별한 행동을 고려한 코드를 작성할 필요가 없다. 종료, join, detach 에 대한 결정은 이미 해당 std::thread를 조작하는 코드에서 내려지기 때문이다.


## Item 39. 단발성 사건 통신에는 void 미래 객체를 고려하라

스레드간 통신을 위해 **조건 변수(condition variable, condvar)** 을 사용한다. 
조건을 검출하는 과제를 **검출 과제(detecting task)** 라고 부르고, 그 조건에 반응하는 과제를 **반응 과제(reacting task)** 라고 부르기로 하면 다음과 같은 예시를 들 수 있다.

#### 예시
반응 과제는 하나의 조건 변수 wait, 검출 과제는 사건이 발생하면 그 조건 변수를 통지하는 예시이다.

```cpp
std::condition_variable cv; 
std::mutex m; 

// 검출 과제 코드
... 				// 사건 검출 
cv.notify_one(); 	// 반응 과제에게 알림


// 반응과제 코드
...										// 반응 준비
{ 										// 임계 영역을 연다 
	std::unique_lock<std::mutex> lk(m); // 뮤텍스를 잠근다 
	cv.wait(lk); 		// 통지를 기다린다 (제대로 된 방식이 아님!) 
	... 				// 사건에 반응한다 (m 이 잠긴 상태) 
}	// 임계 영역을 닫고, lk 의 소멸자가 m 을 해제
// 계속 반응한다 (m 은 이제 풀린 상태) 
...
```

위의 코드는 뮤택스가 필요 없을 수 있는 잠재적인 코드 냄새 가능성이 있고, 다른 두 가지 문제점도 있다.
- **만일 반응 과제가 wait 을 실행하기 전에 검출 과제가 조건 변수를 통지하면 반응 과제가 멈추게 된다(hang).**
	- 통지를 놓지게 되며, 영원히 통지를 기다리게 된다
- **wait 호출문은 가짜 기상을 고려하지 않는다.**
	- 조건 변수를 기다리는 코드가 조건 변수가 통지되지 않았는데도 깨어날 수 있다는 것은 흔히 있는 일이다. 이런 일을 가짜 기상이라고 부른다.
	- 이는 자신이 기다리는 조건이 참인지를 반응 과제가 판단할 수 있어야 하는데, 불가능함.

#### 플래그 기반 설계 대안

아래의 코드는 조건 변수 기반 설계의 단점은 없지만, 반응 과제의 풀링(주기적 점검) 비용이 매우 큼.
```cpp
// 검출 스레드
std::atomic<bool> flag(false);	// 공유 플래그
... // 사건을 검출
flag = true;	// 반응 과제에 통지


// 반응 스레드
... // 반응 준비
while(!flag); // 사건을 기다림
...	// 사건에 반응
```

#### 조건 변수 기반 설계와 플래그 기반 설계 결합

아래의 코드는 검출 과제는 사건이 확실히 발생했음을 플래그로 반응 과제에게 알려주지만, 반응 과제가 그 플래그를 점검하게 하려면 먼저 조건 변수를 통지해서 반응 과제를 깨워야 한다. 
```cpp
// 검출 과제
std::condition_variable cv;
std::mutex m;
bool flag(false);

... // 사건 검출
{
	std::lock_guard<std::mutex> g(m); // g의 생성자에서 m을 잠금
	flag = true;	// 반응 과제에게 통지 ( 1부 )
}	// g 소멸자에서 m 을 푼다.
cv.notify_one();	// 반응 과제에게 통지 ( 2부 )

// 반응 과제
... // 반응 준비
{
	std::unique_lock<std::mutex> lk(m); 
	cv.wait(lk, [] { return falg; }); // 가짜 기상 방지
	... // 사건에 반응 ( m 잠긴 상태 )
}
.. // 계속 반응 ( m 풀린 상태 )
```

#### 검출 과제가 설정한 미래객체 대안

또 다른 대안으로는 다음과 같다. 
- 검출 과제에는 std::promise 객체(통신 채널의 전송단자)를 하나 두고, 반응 과제에서는 그에 대응되는 미래 객체를 하나 둔다. 
- 기다리던 사건이 발생했음을 인식하면 검출 과제는 자신의 std::promise 를 설정한다(즉, 통신 채널에 정보를 기록). 
- 그동안 반응 과제는 자신의 미래 객체에 대해 wait 를 호출해둔 상태이고 std::promise 가 설정될 때까지 차단된다.

```cpp
// 검출 과제
std::promise<void> p;	// 통신 채널에서 사용할 객체
... // 사건 검출
p.set_value(); // 반응 과제에게 통지

// 반응 과제
... // 반응 준비
p.get_future().wait(); // p에 해당하는 미래 객체를 기다림
... // 사건에 반응
```
- 장점 : 뮤텍스 필요 X, 반응 과제가 wait 으로 대기하기 전에 검출 과제가 std::promise 를 설정해도 작동하며, 가짜 기상도 없다(조건 변수에서만 발생). 그리고 wait 호출 후 반응 과제는 차단되므로 시스템 자원도 소모하지 않는다.
- 단점 : std::promise 는 한 번만 설정할 수 있다. 즉 std::promise 와 미래 객체 사이의 통신 채널은 여러 번 사용할 수 없는 단발성 매커니즘이다.


## Item 40. 동시성에는 std::atomic을 사용하고, volatile은 특별한 메모리에 사용하라

### std::atomic

std::atomic 는 뮤텍스 보호 없이 여러 스레드가 접근하기 위한 자료를 위한 것이다. std::atomic 객체가 성공적으로 생성되고 나면, 그 객체에 대한 연산은 마치 뮤텍스로 보호되는 임계 영역(critical section) 안에서 수행되는 것처럼 작동한다. 보통 뮤텍스보다 더 효율적인 특별한 기계어 명령들로 구현된다.

```cpp
std::atomic<int> ai(0);	// ai를 0으로 초기화
ai = 10;				// 원자적으로 ai를 10으로 설정한다.

std::cout << ai;		// 원자적으로 ai의 값을 읽는다.
++ai;					// 원자적으로 ai를 증가한다 (11)
--ai;					// 원자적으로 ai를 감소한다. (10)
```
위의 코드에서 주목할 점이 두 가지 있다.

1. "std::cout << ai;" 문장에서 ai 가 std::atomic 객체라는 점이 보장하는 것은 ai 의 읽기가 원자적이라는 것 뿐이다. ai 의 값을 읽는 시점과 operator<< 가 호출되어서 ai의 값이 표준 출력에 기록되는 시점 사이에 다른 스레드가 ai 의 값을 수정할 수도 있다. 그 점이 이 문장의 행동에 영향을 미치진 않는다. 애초에 ai 에서 읽은 값이 출력된다. 그러나 이 문장에서 원자적인 부분은 오직 ai 를 읽는 부분이라는 점이다.
2. "++ai;" / "--ai;" 의 행동을 주목할 필요가 있다. 증가 연산이나 감소 연산은 읽기-수정-쓰기 (read-modify-write, RMW) 연산이지만, 각각 원자적으로 수행된다. 일단 std::atomic 객체가 생성되고 나면, 그 객체에 대한 모든 멤버 함수는, 심지어 RMW 연산들을 수행하는 멤버 함수도, 다른 스레드들에게 반드시 원자적으로 보인다.

### volatile

반면 volatile 을 사용하는 다음과 같은 코드는 다중 스레드 문맥에서 거의 아무것도 보장하지 않는다.

```cpp
volatile int vi(0);		// vi를 0으로 초기화
vi = 10;				// vi를 10으로 설정한다.

std::cout << vi;		// vi의 값을 읽는다.
++vi;					// vi를 증가한다 (11)
--vi;					// vi를 감소한다. (10)
```

위의 코드를 실행하는 동안 vi 의 값을 다른 스레드에서 읽는다면, 그 스레드들은 그 어떤 값이라도 볼 수 있고, 이런 코드는 미정의 행동을 유발한다. 이 코드는 vi 를 수정하므로, 동시에 다른 스레드들이 vi 를 읽는다면, 뮤텍스로 보호되지 않은 메모리에 기록자(writer)와 판독자(reader) 들이 동시에 접근하려 해서 자료 경쟁(data race)가 일어난다.


### 다중 스레드 프로그램에서 std::atomic 과 volatile 행동의 차이

#### RMW 연산
```cpp
std::atomic<int> ac(0);
volatile int vc(0);

/* 스레드 1 */	/* 스레드 2*/
   ++ac;           ++ac;
   ++vc;		   ++vc;

// 스레드들이 동시에 실행됨
```
두 스레드 모두 실행이 끝난 뒤 ac 의 값은 반드시 2 이지만, vc 의 값은 2일 수도 있고 아닐 수 도 있다. vc 의 값을 읽고, 그 값을 증가하고, 그 결과를 다시 vc 에 기록하는 연산들이 volatile 객체에 대해 원자적으로 진행된다는 보장이 없기 때문이다.

#### 코드 순서 재배치

한 과제가 어떤 중요한 값을 계산 / 둘째 과제가 그 값을 자신의 작업에 사용한다고 하자. 첫 과제가 값을 다 계산했으면 그것을 둘째 과제에게 알려 주어야 하는 방법은 std::atomic<bool>을 이용한다고 하자. 

```cpp
// 1번 코드
std::atomic<bool> valAvailable(false);
auto imptValue = computeImportantValue();
valAvilable = true;

// 2번 코드
volatile bool valAvailable(false);
auto imptValue = computeImportantValue();
valAvilable = true;
```
컴파일러는 imptValue 배정과 valAvilable 배정문을 단지 서로 독립적인 변수에 대한 두 배정으로 보기 때문에 서로 무관한 배정들의 순서를 컴파일러가 임의로 바꿀 수 있다. 
이때 1번 코드처럼 std::atomic 을 사용한다면 코드 순서 재배치에 대한 제약을 부여하지만, 2번 코드처럼 volatile 을 사용한다면 그러한 제약이 없어 코드 순서 재배치가 될 가능성이 있다.

### volatile 이 필요한 경우
volatile 은 volatile 이 적용된 변수는 보통의 방식으로 행동하지 않음을 컴파일러에게 알려준다. 
'보통' 메모리에는 메모리의 한 장소에 어떤 값을 기록하면 다른 어떤 값을 덮어쓰지 않는 한 그 값이 유지된다. 또한 어떤 메모리 장소에 어떤 값을 기록한 후 그 값을 한번도 읽지 않고 그 메모리 장소에 값을 기록한다면 첫 번째 기록은 제거할 수 있다.
```cpp
int x;
auto y = x;
y = x;

x = 10;
x = 20;
```
위의 코드의 2, 3 번째 줄은 동일한 일을 하기 때문에, 컴파일러가  3번째 줄을 제거하여 최적화할 수 있다. 
또한 5, 6번째 줄에서 x 를 기록하는데, 컴파일러가 5번째 줄을 제거할 수 있다. 

지금까지 말한 최적화들은 메모리가 보통의 방식으로 행동할 때만 유효하다. 그러나 `메모리 대응 입출력(memory-mapped I/O)`와 같은 '특별한' 메모리는 그런 식으로 행동하지 않는다. 그런 메모리에 있는 장소들에 대한 접근은 보통의 메모리를 읽거나 쓰는 것이 아니라, 외부 감지기나 디스플레이, 프린터와 같은 주변 장치와 실제로 통신한다. 

예를 들어, 2/3번째 줄 사이에서 x의 값이 변했을 수도 있는 경우(온도계), 5/6번째 줄에서의 배정이 꼭 필요한 경우(무선통신) 최적화로 제거되면 안되는 코드가 된다. 이런 경우 x 를 volatile 로 만들어 주어야 한다.

```cpp
volatile int x;
auto y = x;	// x 를 읽는다
y = x;		// x 를 다시 읽는다 (최적화로 제거X)

x = 10;		// x 를 기록한다 (최적화로 제거X)
x = 20;		// x 를 다시 기록한다
```

#### std::atomic  사용할 경우
```cpp
std::atomic<int> x;
auto y = x;	// 오류
y = x;		// 오류

x = 10;		
x = 20;		
```
x 가 std::atomic 일 경우 컴파일 에러가 발생한다. 이는 std::atomic 의 복사 연산들이 삭제되었기 때문이다(이동 연산도 제공 X).  

```cpp
std::atomic<int> x;
std::atomic<int> y(x.load());
y.store(x.load());
```
위와 같이 코드를 수정하면 컴파일이 되긴 하지만, x 를 읽는 연산과 그 값으로 y를 초기화하는 연산 또는 y에 저장하는 연산이 개별적인 함수 호출들이므로, 두 문장이 각자 하나의 원자적 연산으로 실행되리라고 기대할 수 없다.

#### std::atomic 과 volatile 의 용도
- std::atomic은 동시적 프로그래밍에 유용
- volatile 은 특별한 메모리 접근에 유용
- 용도가 다르므로 함께 사용 가능
```cpp
// 여러 스레드가 동시에 접근할 수 있는 메모리 대응 입출력 장소 일때 유용
volatile std::atomic<int> vai; // vai에 대한 연산들은 원자적이며,
							   // 최적화에 의해 제거될 수 없다
```




# 8장 다듬기

## Item 41. 이동이 저렴하고 항상 복사되는 복사 가능 매개변수에 대해서는 값 전달을 고려하라

다음과 같이 함수 매개변수 중 애초에 복사되도록 만들어진 것들이 존재하는데, 효율성을 위해 다음과 같이 구현할 수 있음.

```cpp
// 1번 코드
class Widget{
public:
	void addName(const std::string& newName) // 왼값을 받아 복사
	{ names.push_back(newName); }
	void addName(std::string&& newName)		// 오른값을 받아 이동
	{ names.push_back(std::move(newName)); } 
	...
private:
	std::vector<std::string> names;
};

//2번 코드
class Widget {
public:
	template<typename T>
	void addName(T&& newName)	// 왼값은 복사 / 오른값은 이동
	{
		names.push_back(std::forward<T>(newName));
	}
	...
};

//3번 코드
class Widget {
public:
	void addName(std::string newName)			// 왼값이나 오른값을 받아 이동
	{ names.push_back(std::move(newName)); }
	...
};

Widget w;
std::string name("Bart");
w.addName(name);			// 왼값 전달
w.addName(name + "Jenne");	// 오른값 전달
```
1. 왼값 / 오른값 버전을 따로 구현한다. 하지만 각각 버전으로 두 개씩 만들어야해서 유지보수의 불편하다.
그리고 함수가 인라인화 되지 않는다면, 목적 코드(object code)에도 함수가 두 개가 존재한다. 
2. 보편 참조를 받는 함수 템플릿으로 구현한다. 하지만 이는 std::string 과 std::string 으로 변환 가능한 형식들에 대해서도 다르게 인스턴스화가 되고(항목 25 참조), 보편참조로 전달할 수 없는 인수 형식들이 존재한다( 항목 30 참조 ).
3. 값으로 전달하는 방식으로 구현한다. 이는 보편 참조의 골칫거리도 피할 수 있고, 함수도 하나만 구현하면 된다.
c++98에서는 값 전달이 항상 복사 생성을 호출하였지만, c++11에서는 인수가 왼값일 때만 복사 생성되고, 오른값일 때에는 이동 생성 된다.


#### 비용 분석
- 중복 적재 구현
	- 왼값의 경우 복사 1회, 오른값의 경우 이동 1회
- 보편 참조 구현
	- 왼값의 경우 복사 1회, 오른값의 경우 이동 1회
- 값 전달 구현
	- 왼값의 경우 복사 1회 이동 1회, 오른값의 경우 이동 2회

**제목처럼 이동이 저렴하고 항상 복사되는 복사 가능 매개변수에 대해서는 값 전달을 *고려*하라**

1. 값 전달을 "사용하라"가 아닌 **고려하라**일 뿐이다. 값 전달 방식에는 함수를 하나만 작성하면 된다는 것과 보편 참조와 관련된 문제가 없는 장점이 있지만, 다른 대안에 비해 비용이 크다.
2. **복사 가능 매개변수**에 대해서만 값 전달을 고려해야 한다. 만약 이동 연산만 지원하는 경우, 중복 적재 버전도 오른값만 받는 버전 하나만 구현하면 된다. 또한 비용도 중복 적재 방식의 두 배인 이동 생성 2회가 발생한다. 
3. 값 전달은 **이동이 저렴한** 매개변수에 대해서만 고려해야 한다. 이동이 저렴한 경우 1번 더 일어난다고 해도 큰 문제가 없지만, 비용이 크다면 불필요한 이동을 수행하는 것은 불필요한 복사를 수행하는 것과 비슷하다.
4. 값 전달은 **항상 복사되는** 매개변수에 대해서만 고려해야 한다. 
	-	예를 들어, addName 코드에서 일정 길이 조건을 만족해야 추가한다고 하자. 이때, 값 전달의 경우 조건 만족 여부와 상관없이 값을 복사해야 하지만, 참조 전달 접근 방식은 그런 비용을 지불할 필요가 없다.

또한 이동이 저렴한 복사 가능 형식에 대해 항상 복사를 수행하는 함수라고 해도 값 전달이 적합하지 않은 경우가 존재한다. 이는 함수가 매개변수를 복사하는 방식이 두 가지이기 때문이다. 하나는 생성을 통한 복사, 또 하나는 배정을 통한 복사 이다. 이때 배정을 통해 복사하는 함수의 경우, 비효율성이 더 증가할 수 있다.

```cpp
class Password {
public:
	explicit Password(std::string pwd)
	: text(std::move(pwd)) {}
	void changeTo(std::string newpwd)
	{ text = std::move(pwd); }
	...
private:
	std::string text;
};

std::string initPwd("supercalifragilisticexxpialidocious");
Password p(initPwd);

std::string newPassword = "beware the jabberwock";
p.changeTo(newPassword);
```
위의 코드에서 changeTo 가 매개변수 newPwd를 복사하려면 배정을 수행해야 하며, 그러면 함수의 값 전달 접근 방식 때문에 비용이 아주 커질 수 있다. newPwd 가 복사 생성으로 생성되면서 메모리에 할당되고, 이를 text 로 이동 배정된다. 이때 text 가 차지하고 있던 메모리가 해제되므로 동적 메모리 관리 동작이 두 번 일어난다. 중복 적재 버전의 경우 메모리를 재사용할 수도 있다. 따라서 최대한 빨라야 하는 소프트웨어에서는 값 전달 방식이 바람직하지 않다.

마지막으로, 참조 전달과 달리 값 전달에서는 잘림 문제(slicing problem)이 발생할 여지가 있다. 함수가 기반 클래스 형식이나 그로부터 파생된 임의의 형식의 매개변수를 받는 경우에는 그 매개변수를 값 전달 방식으로 선언하지 않는 것이 좋다. 만일 값 전달로 선언하면, 파생 형식의 객체가 전달되었을 때 그 객체의 파생 클래스 부분이 잘려나간다.
```cpp
class Widget {...};
class SpecialWidget: public Widget {...};
void processWidget(Widget w);

SpecialWidget sw;

processWidget(sw); // Widget 으로 인식
```


## Item 42. 삽입 대신 생성 삽입을 고려하라

#### 문제 예시 코드 - push_back
```cpp
std::vector<std::string> vs;
vs.push_back("xyzzy");	// 문자열 리터럴을 추가한다
```
```cpp
vs.push_back(std::string("xyzzy"));
```
인수의 형식이 const char[6] 이고 push_back 이 받는 매개변수의 형식은 std::string 이라 일치하지 않는다. 

1. 문자열 리터럴 "xyzzy" 로부터 임시 std::string 객체 temp 생성
2. temp 가 push_back 의 오른값 오버로딩으로 전달 ->  temp 는 오른값 참조 매개변수 x 에 묶임
-> std::vector 를 위한 메모리 안에서 x의 복사본 생성 
3. push_back 이 반환된 즉시 temp 가 파괴되어 std::string 소멸자가 실행

#### 수정된 예시 코드 - emplace_back

```cpp
vs.emplace_back("xyzzy");
```
 emplace_back을 사용하면, 임시 객체를 만들지 않고 완벽 전달을 통해 std::vector 안에서 직접 std::string 생성한다.
 - push_back 을 지원하는 모든 표준 컨테이너는 emplace_back 지원, push_front 도 마찬가지로 emplace_front 지원
 - insert 를 지원하는 모든 표준 컨테이너(std::forward_list, std::array 제외)는 emplace 를 지원

이런 emplace 류 함수들을 생성 삽입(emplacement) 함수라고 한다. 삽입 함수들은 **삽입할 객체**를 받지만 생성 삽입 함수는 **삽입합 객체의 생성자를 위한 인수들**을 받는다.

삽입 함수가 임시 객체를 필요로 하지 않는 경우에도 생성 삽입 함수를 사용할 수 있다. 이런 경우 두 함수는 동일한 일을 한다. 따라서 생성 삽입 함수들은 삽입 함수들이 하는 모든 일을 할 수 있다.

```cpp
std::string queenOfDisco("Donna Summer");
vs.push_back(queenOfDisco);		// vs 에서 복사 생성 1회
vs.emplace_back(queenOfDisco);	// 마찬가지
```

#### 생성 삽입 함수 사용 조건

이론적으론 생성 삽입 함수가 삽입 함수보다 더 성능이 좋다. 하지만 실제는 다양한 요인으로 인해 반대의 경우도 일어난다. 즉, 생성 삽입과 삽입 중 어느 것이 빠른지는 성능 체크를 해봐야 알 수 있다.
하지만 일반적으로 다음 세 조건이 성립한다면, 거의 항상 생성 삽입이 삽입 함수보다 성능이 좋다.

1. **추가할 값이 컨테이너에 배정되는 것이 아니라 컨테이너 안에서 생성된다.**
-	처음 제시한 예제의 경우이다. "xyzzy" 값은 std::vector인 vs 끝에, 아직 어떤 객체도 존재하지 않는 곳에 추가된다. 따라서 새 값은 std::vector 안에 생성된다.
-	하지만 다음과 같이 배정의 경우, 이동 배정 시 이동 원본이 될 임시 객체를 생성해야 하므로, 성능 상의 이점이 없다.
```cpp
std::vector<std::string> vs;
...								 // 요소들을 vs 에 추가
vs.emplace(vs.begin(), "xyzzy"); // vs 의 시작에 추가
```
- 노드 기반 컨테이너들은 거의 항상 생성을 통해 새 값을 추가하며, 표준 컨테이너들은 대부분 노드 기반이다. 
- 노드 기반이 아닌 표준 컨테이너 std::vector, std::deque, std::string 뿐이고, emplace_back 이 항상 배정 대신 생성을 이용해서 새 값을 추가한다. 

2. **추가할 인수 형식(들)이 컨테이너가 담는 형식과 다르다.**
임시 객체의 생성과 파괴가 일어나지 않아 성능이 좋다.

3. **컨테이너가 기존 값과의 중복 때문에 새 값을 거부할 우려가 별로 없다.**
이는 컨테이너가 중복을 허용하거나, 또는 추가할 값들이 대부분 고유한 경우에 해당한다.
중복 제한이 있으면 생성 삽입 구현은 새 값으로 노드를 생성하고, 기존 컨테이너 노드들과 비교한다.
값이 이미 있으면 생성 삽입이 취소되고, 노드가 파괴되므로, 생성과 파괴 비용이 발생한다. 

4. 또한 다음 두 가지 사항도 고려하는 것이 좋다.
- 자원 관리

```cpp
std::list<std::shared_ptr<Widget>> ptrs; 
void killWidget(Widget* pWidget);	// 커스텀 삭제자
ptrs.push_back(std::shared_ptr<Widget>(new Widget, killWidget)); // 삽입 버전  
ptrs.push_back({new Widget, killWidget}); // 간단한 버전 
ptrs.emplace_back(new Widget, killWidget); // 생성 삽입 버전 
```

다음과 같은 상황이 발생했을 때, 

push_back 의 경우 메모리 누수가 발생하지 않는다.

	1. std::shared_ptr<Widget> 객체 생성, 이를 temp 라고 하자.
	2. push_back 은 temp 를 참조로 받는다. temp 복사본을 담을 노드 할당 중 메모리 부족 예외 발생
	3. 예외가 push_back 바깥으로 전파되면서 temp 파괴, 동시에 Widget 도 자동으로 해제(killWidget)

emplace_back 의 경우 메모리 누수가 발생한다.

	1. "new Widget" 으로 만들어진 생 포인터가 emplace_back 으로 완벽 전달. 
	    새 값을 담을 목록 노드를 할당하려고 하지만 메모리 부족 예외가 발생
	2. 예외가 emplace_back 밖으로 전파되면서, 힙에 있는 Widget 객체에 도달하는 생 포인터가 사라짐.
	   결국 Widget 의 자원이 누수됨.

따라서, 이 경우에는 항목 21에서 설명하듯이, "new Widget" 을 바로 전달하지 말고, 별도의 문장으로 분리하는 것이 바람직하다. 다음 코드 모두, spw 의 생성과 파괴의 비용이 발생하며 성능 상의 큰 차이가 없다.
```cpp
// 삽입 버전  
std::shared_ptr<Widget> spw1(new Widget, killWidget); 
ptrs.push_back(std::move(spw1)); 
// 생성 삽입 버전  
std::shared_ptr<Widget> spw2(new Widget, killWidget); 
ptrs.emplace_back(std::move(spw2));
```


### explicit 생성자들과의 상호작용 방식

#### 정규표현식을 이용한 예제

```cpp
std::vector<std::regex> regexes; 
 
std::regex upperCaseWord("[A-Z]+"); // 정상 작동  
std::regex r = nullptr; 			// 오류! 컴파일 안됨! 
regexes.push_back(nullptr); 		// 오류! 컴파일 안됨! 
regexes.emplace_back(nullptr); 		// ??? : 컴파일 됨 
```

- 위의 생성자와  push_back 이 실패하는 이유는 생성자가 explicit 로 되어 있어 컴파일러가 변환을 거부 ( std::regex 는 생성자 인수로 const char* 를 받음)
- 반면 emplace_back 은 std::regex 객체의 생성자에 전달한 인수이므로, 다음 코드처럼 취급된다.
```cpp
std::regex r(nullptr);
```
- 위의 코드가 컴파일 되는 이유는 다음과 같다. explicit 생성자에서는 복사 초기화를 사용할 수 없지만, 직접 초기화는 사용할 수 있다. 만약 emplace_back 으로 nullptr 을 전달한 경우, 프로그램은 미정의 행동을 하게 된다.
- 따라서 생성 삽입 함수를 사용할 때에는 제대로 된 인수를 넘겨주는데 특별히 신경을 써야 한다.
```cpp
// 복사 초기화
std::regex r1 = nullptr; 	// 오류! 컴파일 안됨
// 직접 초기화
std::regex r2(nullptr);		// 컴파일 됨, 미정의 행동 포함
```

